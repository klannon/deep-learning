# ---------------------------------------------------------------------
# Trains a neural network on the run_3v data generated by OSU
#
# Author: Colin Dablain
#
# This script borrows heavily from Peter Sadowski's
# https://github.com/klannon/higgs-susy/blob/master/physics.py
# ---------------------------------------------------------------------

from pylearn2.datasets import dense_design_matrix
from pylearn2.datasets import control
from pylearn2.utils import serial
import os
import numpy as np
import pickle as pkl
import csv
from os import sep

def PHYSICS(pathToTrainValidData, pathToTestData, trainFraction):
    train, valid  = csv.getData(pathToTrainValidData, trainFraction)
    test = csv.getData(pathToTestData)
    return (_PHYSICS(train, 'train'),
            _PHYSICS(valid, 'valid'),
            _PHYSICS(test, 'test'))

class _PHYSICS(dense_design_matrix.DenseDesignMatrix):
    def __init__(self, data, which_set):
        # Need to allocate two arrays X (inputs) and y (targets)
        print("Data loaded: %s" % which_set)

        # Initialize the superclass. DenseDesignMatrix
        super(_PHYSICS, self).__init__(X=data['data'], y=data['labels'].reshape(len(data['labels']), 1))
        
    def standardize(self, X):
        """
        Standardize each feature:
        1) If data contains negative values, we assume its either normally or uniformly distributed, center, and standardize.
        2) elseif data has large values, we set mean to 1.
        """
        
        for j in range(X.shape[1]):
            vec = X[:, j]
            if np.min(vec) < 0:
                # Assume data is Gaussian or uniform -- center and standardize.
                vec = vec - np.mean(vec)
                vec = vec / np.std(vec)
            elif np.max(vec) > 1.0:
                # Assume data is exponential -- just set mean to 1.
                vec = vec / np.mean(vec)
            X[:,j] = vec
        return X
